{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from selenium.webdriver.edge.options import Options\n",
    "import os\n",
    "from selenium.webdriver.edge.service import Service as EdgeService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_last_category():\n",
    "    try:\n",
    "        with open(category_file_path, 'r') as file:\n",
    "            return int(file.read().strip())\n",
    "    except FileNotFoundError:\n",
    "        with open(category_file_path, 'w') as file:\n",
    "            file.write(\"0\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_last_page(page_number):\n",
    "    with open(page_file_path, 'w') as file:\n",
    "        file.write(str(page_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_last_page():\n",
    "    try:\n",
    "        with open(page_file_path, 'r') as file:\n",
    "            return int(file.read().strip())\n",
    "    except FileNotFoundError:\n",
    "        with open(page_file_path, 'w') as file:\n",
    "            file.write(\"1\")\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_data_to_csv(filename, data):\n",
    "# Writing data to the file and adding it over the previous data\n",
    "    with open(filename, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Enter the data here as you wish.\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create browser\n",
    "browser = webdriver.Edge()\n",
    "\n",
    "# Read last page number\n",
    "page_number1 = read_last_page()\n",
    "# filename = 'products_data.xlsx'\n",
    "filename_cvs= 'products_data_Supplements.csv'\n",
    "column_titles = ['title', 'product_info_link', 'product_info_name', 'product_info_image', 'product_info_current_price_price', 'product_info_original_price', 'product_info_rating', 'product_info_rating_count']\n",
    "base_url1 = 'https://....'\n",
    "categories = ['categories']\n",
    "number = [0]\n",
    "page_file_path = \"last_page.txt\"\n",
    "category_file_path = \"last_category.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(filename_cvs):\n",
    "    # Open the file for writing and write the column headers.\n",
    "    with open(filename_cvs, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(column_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scroll through pages\n",
    "for page_number in range(page_number1, 42):\n",
    "    if page_number == 1 :\n",
    "        url = f'https://.....'\n",
    "    else:\n",
    "        url = f'https:....?p={page_number}'\n",
    "    \n",
    "    browser.get(url)  # Open page\n",
    "    \n",
    "    # Scroll down the page\n",
    "    browser.find_element(By.TAG_NAME, 'body').send_keys(Keys.END)\n",
    "    time.sleep(1)  # Wait for new content to load.\n",
    "    \n",
    "    try:\n",
    "        # Extract and parse page source\n",
    "        page_source1 = browser.page_source\n",
    "        content = BeautifulSoup(page_source1, 'html.parser')\n",
    "        page_source1 = content.body.find('div', {'class':'products','class':'product-cells','class':'clearfix'})\n",
    "        \n",
    "        if not page_source1:\n",
    "            print(\"Not_Found\")\n",
    "        else:\n",
    "            products_product_inner = page_source1.find_all('div', {'class': 'product-inner'})\n",
    "            if not products_product_inner:\n",
    "                print(f\"Failed to fetch page {page_number}\")\n",
    "            else:\n",
    "                for product in products_product_inner:\n",
    "                    title1 = browser.title\n",
    "                    # Extract link and name\n",
    "                    linke = product.find('a', {'class': 'absolute-link product-link'})\n",
    "                    if not linke:\n",
    "                            print(\"0\")\n",
    "                            product_info_link = 'NotFound'\n",
    "                            product_info_name = 'NotFound'\n",
    "                    else:\n",
    "                        product_info_link = linke.get('href')\n",
    "                        product_info_name =  linke.get('aria-label').strip() \n",
    "                    \n",
    "                    #Extract product image\n",
    "                    image = product.find('img')\n",
    "                    if image:\n",
    "                        product_info_image = image.get('src', '').strip()\n",
    "                    else:\n",
    "                        product_info_image = 'NotFound'\n",
    "                    \n",
    "                    # Extract current price and original price\n",
    "                    price = product.find('span', {'class': 'price'})\n",
    "                    if price:\n",
    "                        product_info_current_price_price = price.get_text(strip=True)\n",
    "                    else:\n",
    "                        price = product.find('span', {'class': 'price discount-green'})\n",
    "                        if price:\n",
    "                            product_info_current_price_price = price.get_text(strip=True)\n",
    "                        else:\n",
    "                            product_info_current_price_price = 'NotFound'\n",
    "                    \n",
    "                    original_price = product.find('span', class_='price-olp')\n",
    "                    if original_price:\n",
    "                        product_info_original_price = original_price.get_text(strip=True)\n",
    "                    else:\n",
    "                        product_info_original_price = 'NotFound'\n",
    "                    \n",
    "                    # Extract rating and number of ratings\n",
    "                    rating = product.find('div',{'class':'rating'})\n",
    "                    if rating:\n",
    "                        star_rating = rating.find('a', {'class':'stars'})\n",
    "                        if star_rating:\n",
    "                            product_info_rating = star_rating.get('title', '').split(' - ')[0].strip()\n",
    "                        else:\n",
    "                            product_info_rating = 'NotFound'\n",
    "                        \n",
    "                        rating_count = rating.find('a', {'class':'rating-count'})\n",
    "                        if rating_count:\n",
    "                            product_info_rating_count = rating_count.find('span').get_text(strip=True)\n",
    "                        else:\n",
    "                            product_info_rating_count = 'NotFound'\n",
    "                    else:\n",
    "                        product_info_rating = 'NotFound'\n",
    "                        product_info_rating_count = 'NotFound'\n",
    "                    \n",
    "                    data = [title1, product_info_link, product_info_name, product_info_image, product_info_current_price_price, product_info_original_price, product_info_rating, product_info_rating_count]\n",
    "                    # add_data_to_excel(filename, data)\n",
    "                    add_data_to_csv(filename_cvs, data)\n",
    "                print(f\"Finish{page_number}\")\n",
    "                write_last_page(page_number)\n",
    "    except TimeoutException:\n",
    "        print(f\"The wait time has expired and the item was not found on the page.{page_number}\")\n",
    "# write_last_page(page_number)\n",
    "browser.quit()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
